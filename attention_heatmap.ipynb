{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dfde4c-7721-4311-a040-4845fcd6c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba18c156-5de3-4778-91eb-e1fc3aed4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datasets\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06b90c-268a-4b0e-a1f5-330230a13a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if(torch.cuda.is_available()):\n",
    "    device = 'cuda'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cbf88-8042-46be-9085-658c63f7b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "base_model_name = \"./Llama-3.2-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  \n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    attn_implementation=\"eager\",          \n",
    "    output_attentions=True, \n",
    "    quantization_config = quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5bf3d-d662-48e7-a4b2-3fa7f93f53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Sentiment_Emotion/dataset/sentiment_test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56404eb0-201d-48ca-861e-a3b812bb2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = datasets.Dataset.from_dict(train_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5751c8e5-ad12-4faa-bf22-6f942ed69a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['Statement'])):       \n",
    "        text = f\"### Question: Classify the sentiment of the following statement into one of the categories: positive or negative. Statement: {example['Reviews'][i]} \\n### Answer: {example['Sentiment'][i]}.\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a155373-de80-4f6f-835b-ca282b956412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "base_model.add_adapter(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babda04-b4d7-475a-9f66-7036716e824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_from_output(text: str, top_k=5):\n",
    "    inputs = tokenizer(text, return_token_type_ids=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = base_model.generate(**inputs, max_new_tokens=1, output_attentions=True, return_dict_in_generate=True)\n",
    "\n",
    "    generated_token = outputs.sequences[:, inputs.input_ids.shape[1]:] \n",
    "\n",
    "    full_input = torch.cat([inputs.input_ids, generated_token], dim=1)  \n",
    "    full_inputs = {\"input_ids\": full_input, \"attention_mask\": torch.ones_like(full_input).to(\"cuda\")}\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        model_outputs = base_model(**full_inputs, output_attentions=True)\n",
    "\n",
    "    attentions = model_outputs.attentions  \n",
    "    last_layer_attention = attentions[-1][0] \n",
    "\n",
    "    output_token_attention = last_layer_attention[:, -1, :-1] \n",
    "\n",
    "    avg_attention_scores = output_token_attention.mean(dim=0) \n",
    "\n",
    "    top_indices = torch.argsort(avg_attention_scores, descending=True)[:top_k]\n",
    "\n",
    "    top_tokens = [tokenizer.convert_ids_to_tokens(full_input[0, idx].item()) for idx in top_indices]\n",
    "    top_tokens = [t.replace(\"Ġ\", \" \") for t in top_tokens]\n",
    "    top_tokens = top_tokens[1:]\n",
    "\n",
    "    print(\"Top 5 input tokens with highest attention to the generated token:\")\n",
    "    for token, score in zip(top_tokens, avg_attention_scores[top_indices]):\n",
    "        print(f\"Token: {token}, Attention Score: {score.item():.4f}\")\n",
    "\n",
    "text = f\"Can't even log in before the app crashes. Sentiment: Negative\"\n",
    "get_attention_from_output(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb90f16-d6c5-4698-a77f-cdd9372ea091",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Can't even log in before the app crashes. Negative\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model_outputs = base_model(**inputs)\n",
    "\n",
    "\n",
    "attentions = model_outputs.attentions\n",
    "last_layer_attention = attentions[-1][0]\n",
    "\n",
    "output_token_attention = last_layer_attention[:, -1, :-1]\n",
    "\n",
    "avg_attention_scores = output_token_attention.mean(dim=0)\n",
    "top_indices = torch.argsort(avg_attention_scores, descending=True)[:7]\n",
    "top_tokens = [tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0, idx].item()) for idx in top_indices]\n",
    "top_tokens = [t.replace(\"Ġ\", \" \") for t in top_tokens]\n",
    "\n",
    "for token, score in zip(top_tokens, avg_attention_scores[top_indices]):\n",
    "    print(f\"Token: {token}, Attention Score: {score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa2618-2487-4f41-bdd5-532564f29187",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_scores = avg_attention_scores[top_indices].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 0.5))\n",
    "sns.heatmap([top_scores[2:]], annot=True, fmt=\".4f\", cmap=\"Blues\", xticklabels=top_tokens[2:], yticklabels=[\"Attention\"], cbar=False, linewidths=0)\n",
    "plt.savefig(\"top5_labels.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e97e3-902b-4751-b09b-169939a664a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I have used a great number of apps from different angles of fitness but by far the Centr app stands alone in its variety, positivity and effectiveness. Positive\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model_outputs = base_model(**inputs)\n",
    "\n",
    "\n",
    "attentions = model_outputs.attentions\n",
    "last_layer_attention = attentions[-1][0]\n",
    "\n",
    "output_token_attention = last_layer_attention[:, -1, :-1]\n",
    "\n",
    "avg_attention_scores = output_token_attention.mean(dim=0)\n",
    "top_indices = torch.argsort(avg_attention_scores, descending=True)[:7]\n",
    "top_tokens = [tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0, idx].item()) for idx in top_indices]\n",
    "top_tokens = [t.replace(\"Ġ\", \" \") for t in top_tokens]\n",
    "# top_tokens = top_tokens[2:]\n",
    "\n",
    "for token, score in zip(top_tokens, avg_attention_scores[top_indices]):\n",
    "    print(f\"Token: {token}, Attention Score: {score.item():.4f}\")\n",
    "\n",
    "top_scores = avg_attention_scores[top_indices].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 0.5))\n",
    "sns.heatmap([top_scores[2:]], annot=True, fmt=\".4f\", cmap=\"Blues\", xticklabels=top_tokens[2:], yticklabels=[\"Attention\"], cbar=False, linewidths=0)\n",
    "plt.savefig(\"top5_labels.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
