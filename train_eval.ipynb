{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db02821-a3ab-46f5-9e3f-eeebcc31860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d25dc-bcd8-45b3-842e-d0a33d3a9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('English_Merged.xlsx'). # Path to the training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1e620-6a85-48ed-8980-14d4dce5bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if(torch.cuda.is_available()):\n",
    "    device = 'cuda'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649650f-f724-40e7-97bc-4314c955f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"meta-llama/Llama-3.2-3B-Instruct\" # Or any other model from HuggingFace\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  \n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    token='',  # Enter HuggingFace access token\n",
    "    quantization_config = quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a0f39b-d632-4713-b56c-8e1eab3f83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    return f\"\"\"### Question: Classify the following financial statement into one of the categories: sustainable or unsustainable, with a short explanation including both positive and negative reasoning. Statement: {example['Statement']} \\n### Answer: {example['Label']}. Positive Reason: {example['Positive Reason']} Negative Reason: {example['Negative Reason']}\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561c3ba2-7724-46b6-84b7-6675941e8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prompt'] = train_df.apply(generate_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4ca68-bee2-4ff7-bd95-1376b3f453fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = datasets.Dataset.from_dict(train_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156a1f93-f711-4f3e-aad1-7770f3b8814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['prompt'])):\n",
    "        output_texts.append(example['prompt'][i])\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69310e72-a7f4-40da-990f-f8f882ae37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "base_model.add_adapter(peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7623940",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea128652-fcc6-40b7-a42b-79f7f696b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = TrainingArguments(\n",
    "    num_train_epochs = 40,\n",
    "    per_device_train_batch_size = 4, \n",
    "    gradient_accumulation_steps = 1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_strategy = \"no\",\n",
    "    logging_steps = 50,\n",
    "    learning_rate = 2e-4,\n",
    "    weight_decay = 0.001,\n",
    "    fp16 = False,\n",
    "    bf16 = False,\n",
    "    max_grad_norm = 0.3,\n",
    "    max_steps = -1,\n",
    "    warmup_ratio = 0.03,\n",
    "    group_by_length = True,\n",
    "    lr_scheduler_type = \"constant\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4f08d-e95b-4d38-bd3e-331b71c50384",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=train_df,\n",
    "    args=train_params,\n",
    "    formatting_func=formatting_prompts_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad62e33-3380-43f7-8087-fad2263735b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526f8a6-507e-42fa-8796-dc1d0db46594",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"final_model\")\n",
    "tokenizer.save_pretrained(\"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e52c23-99ee-443d-b2e8-3d765659b620",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb81440-4b40-43fe-bf8c-2ee09358413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from peft import LoraConfig\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be6432-164d-490c-b926-60b3ac6e0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"test_data_english.csv\") # Path to the test data\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502ae91-58ff-4e3d-a8f2-fd4afee4c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text: str):\n",
    "    inputs = tokenizer(text, return_token_type_ids=False,return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.inference_mode():\n",
    "        outputs = base_model.generate(**inputs, max_new_tokens=5, temperature=0.1)        \n",
    "        answer_tokens = outputs[:, inputs.input_ids.shape[1] :]\n",
    "    return tokenizer.decode(answer_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "\n",
    "for i in range(len(testset['sentence'])):\n",
    "    text = f\"### Question: Classify the following financial statement into one of the categories: 'sustainable' or 'unsustainable,'. Statement: {testset['sentence'][i]} \\n### Answer:\"\n",
    "    \n",
    "    pred = []\n",
    "    processed_output = summarize(text)\n",
    "\n",
    "    if \"unsustainable\" in processed_output:\n",
    "        result = \"unsustainable\"\n",
    "    else:\n",
    "        result = \"sustainable\"\n",
    "\n",
    "    if result == testset['label'][i].lower():\n",
    "        correct = correct+1\n",
    "    total = total + 1\n",
    "\n",
    "    actual = testset['label'][i].lower()\n",
    "\n",
    "    if result == \"sustainable\":\n",
    "        if actual == \"sustainable\":\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    else:\n",
    "        if actual == \"unsustainable\":\n",
    "            TN += 1\n",
    "        else:\n",
    "            FN += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct/total\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
